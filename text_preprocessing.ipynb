{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO2ZowZGsi5JQtYHR+c3IY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshit6322/FASTAPI_LEARN/blob/main/text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tokenize**"
      ],
      "metadata": {
        "id": "RAPlCCh8_WbN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MnKfUGj_A1I",
        "outputId": "7d542572-901c-4048-f70a-b0e33f14c0f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Greek king Midas did a good deed for a Satyr.\n",
            "This prompted Dionysus, the god of wine, to grant him a wish.\n",
            "Mida's asked for everything he touched to turn to gold.\n",
            "Dionysus’ warned him not to do so, but Midas could not be swayed. \n",
            "Midas excitedly started touching everything and turning them into gold. \n",
            "Soon, he became hungry.\n"
          ]
        }
      ],
      "source": [
        "paragraph =\"\"\"The Greek king Midas did a good deed for a Satyr.\n",
        "This prompted Dionysus, the god of wine, to grant him a wish.\n",
        "Mida's asked for everything he touched to turn to gold.\n",
        "Dionysus’ warned him not to do so, but Midas could not be swayed.\n",
        "Midas excitedly started touching everything and turning them into gold.\n",
        "Soon, he became hungry.\"\"\"\n",
        "print(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAAV7flvBAwl",
        "outputId": "c73106ec-f1c3-4669-9a99-56e17aa007f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSQJseL9AlaB",
        "outputId": "cc564f6d-8c0b-4342-98ba-8e22952c74d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The Greek king Midas did a good deed for a Satyr.', 'This prompted Dionysus, the god of wine, to grant him a wish.', \"Mida's asked for everything he touched to turn to gold.\", 'Dionysus’ warned him not to do so, but Midas could not be swayed.', 'Midas excitedly started touching everything and turning them into gold.', 'Soon, he became hungry.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "words = nltk.word_tokenize(paragraph)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_5cIv6dB3cf",
        "outputId": "7afc0ddd-d3bf-4cb6-d19d-c61635f8371a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Greek', 'king', 'Midas', 'did', 'a', 'good', 'deed', 'for', 'a', 'Satyr', '.', 'This', 'prompted', 'Dionysus', ',', 'the', 'god', 'of', 'wine', ',', 'to', 'grant', 'him', 'a', 'wish', '.', 'Mida', \"'s\", 'asked', 'for', 'everything', 'he', 'touched', 'to', 'turn', 'to', 'gold', '.', 'Dionysus', '’', 'warned', 'him', 'not', 'to', 'do', 'so', ',', 'but', 'Midas', 'could', 'not', 'be', 'swayed', '.', 'Midas', 'excitedly', 'started', 'touching', 'everything', 'and', 'turning', 'them', 'into', 'gold', '.', 'Soon', ',', 'he', 'became', 'hungry', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "words = nltk.wordpunct_tokenize(paragraph)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlHwvmwSCCMS",
        "outputId": "cc25f4a0-9674-42ab-9618-65115f524b93"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Greek', 'king', 'Midas', 'did', 'a', 'good', 'deed', 'for', 'a', 'Satyr', '.', 'This', 'prompted', 'Dionysus', ',', 'the', 'god', 'of', 'wine', ',', 'to', 'grant', 'him', 'a', 'wish', '.', 'Mida', \"'\", 's', 'asked', 'for', 'everything', 'he', 'touched', 'to', 'turn', 'to', 'gold', '.', 'Dionysus', '’', 'warned', 'him', 'not', 'to', 'do', 'so', ',', 'but', 'Midas', 'could', 'not', 'be', 'swayed', '.', 'Midas', 'excitedly', 'started', 'touching', 'everything', 'and', 'turning', 'them', 'into', 'gold', '.', 'Soon', ',', 'he', 'became', 'hungry', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "words = tokenizer.tokenize(paragraph)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2RUCzgEC-XT",
        "outputId": "8f7ec541-f83a-4e57-d6d1-671fc361a9aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Greek', 'king', 'Midas', 'did', 'a', 'good', 'deed', 'for', 'a', 'Satyr.', 'This', 'prompted', 'Dionysus', ',', 'the', 'god', 'of', 'wine', ',', 'to', 'grant', 'him', 'a', 'wish.', 'Mida', \"'s\", 'asked', 'for', 'everything', 'he', 'touched', 'to', 'turn', 'to', 'gold.', 'Dionysus’', 'warned', 'him', 'not', 'to', 'do', 'so', ',', 'but', 'Midas', 'could', 'not', 'be', 'swayed.', 'Midas', 'excitedly', 'started', 'touching', 'everything', 'and', 'turning', 'them', 'into', 'gold.', 'Soon', ',', 'he', 'became', 'hungry', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk."
      ],
      "metadata": {
        "id": "y3Pm5K62DMnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQAi3yWJD5vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**stemming**"
      ],
      "metadata": {
        "id": "358ghqJmEEOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words =verbs = [\n",
        "    \"running\",\"jumped\",\"speak\",\"writing\",\"reads\",\"sang\",\"dancing\",\"eats\",\"drank\",\"slept\",\"laughing\",\"cries\",\"thought\",\"swimming\",\"drove\",\"flies\",\"cooking\",\"history\"]\n"
      ],
      "metadata": {
        "id": "t3zTMnK5EK3o"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMCsDA4JFY4N",
        "outputId": "0261626b-f9b7-4490-dd72-92120249519c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'jump', 'speak', 'write', 'read', 'sang', 'danc', 'eat', 'drank', 'slept', 'laugh', 'cri', 'thought', 'swim', 'drove', 'fli', 'cook', 'histori']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyKDlMyFGGIN",
        "outputId": "42e0a2dd-29c4-4ab5-a167-c9eba7903fc9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'jump', 'speak', 'writ', 'read', 'sang', 'dant', 'eat', 'drank', 'slept', 'laugh', 'cri', 'thought', 'swim', 'drov', 'fli', 'cook', 'hist']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Wg62TWGeE0",
        "outputId": "61ccfb59-f4eb-412d-d107-602d8d92bfdc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'jump', 'speak', 'write', 'read', 'sang', 'danc', 'eat', 'drank', 'slept', 'laugh', 'cri', 'thought', 'swim', 'drove', 'fli', 'cook', 'histori']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**word limitizer**"
      ],
      "metadata": {
        "id": "q-Q2D6liKPHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "\n",
        "stemmer = RegexpStemmer('ning$|ed$|able$|ing$|s$', min=4)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi6rXSiNG0RH",
        "outputId": "558c6a71-e7c0-48cd-9601-1cfd67efa7df"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'jump', 'speak', 'writ', 'read', 'sang', 'danc', 'eat', 'drank', 'slept', 'laugh', 'crie', 'thought', 'swimm', 'drove', 'flie', 'cook', 'history']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Yl0jWwfIg3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPHMJHmBJb__",
        "outputId": "ebfce500-6102-49d0-d478-21d84af1b48f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word,'v') for word in words]\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W_LKcfEInoq",
        "outputId": "dd2813a4-c94f-4c58-f608-50ca57b4cc7f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'jump', 'speak', 'write', 'read', 'sing', 'dance', 'eat', 'drink', 'sleep', 'laugh', 'cry', 'think', 'swim', 'drive', 'fly', 'cook', 'history']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmetizer = WordNetLemmatizer()\n",
        "lemmatized_word = lemmatizer.lemmatize('going',pos ='v')\n",
        "print(lemmatized_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoERjQf4KWgu",
        "outputId": "13bcf5f4-d75f-4fbf-bddb-c9ff18a72f6f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stop Word**"
      ],
      "metadata": {
        "id": "QyRQj6SBLyO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"The quick brown fox jumps over the lazy dog, landing softly on the other side. It runs swiftly across the open field, its paws barely touching the ground as it dodges rocks, trees, and tall grasses. The dog, still lying lazily in the warm sun, only manages to lift its head slightly, watching the fox with half-closed eyes. The fox, sensing no threat, pauses for a moment, glancing back at the dog with curiosity. Then, with a flick of its tail, it disappears into the dense forest, leaving the dog to sigh deeply and return to its peaceful nap, undisturbed by the fleeting encounter. The gentle breeze rustles the leaves, and the scene returns to quiet stillness\"\"\"\n"
      ],
      "metadata": {
        "id": "LD_3coyrL5eJ"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALdzXmWJQjOf",
        "outputId": "0cfa42bc-e678-4d5d-aa90-6814c1b11d9a"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from  nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "khKHn33UMlY0"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.words('english')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vPlMihAPRGll",
        "outputId": "ecd181e6-f485-4035-94da-31ecbeeb188a"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sentance = sent_tokenize(text)\n",
        "\n",
        "sentance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPa-DX-dRktC",
        "outputId": "a5d969d3-fb31-479b-adde-531018ee4f74"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The quick brown fox jumps over the lazy dog, landing softly on the other side.',\n",
              " 'It runs swiftly across the open field, its paws barely touching the ground as it dodges rocks, trees, and tall grasses.',\n",
              " 'The dog, still lying lazily in the warm sun, only manages to lift its head slightly, watching the fox with half-closed eyes.',\n",
              " 'The fox, sensing no threat, pauses for a moment, glancing back at the dog with curiosity.',\n",
              " 'Then, with a flick of its tail, it disappears into the dense forest, leaving the dog to sigh deeply and return to its peaceful nap, undisturbed by the fleeting encounter.',\n",
              " 'The gentle breeze rustles the leaves, and the scene returns to quiet stillness']"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "for i in range(len(sentance)):\n",
        "  words = word_tokenize(sentance[i])\n",
        "  words = [stemmer.stem(word) for word in words if word  not in set(stopwords.words('english'))]\n",
        "\n",
        "  sentance[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "UAeGZfyCSmLw"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfdDYsF3UYny",
        "outputId": "168831ef-847f-4573-86f8-7a8b0599b062"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the quick brown fox jump lazi dog , land soft side .',\n",
              " 'it run swift across open field , paw bare touch ground dodg rock , tree , tall grass .',\n",
              " 'the dog , still lie lazili warm sun , manag lift head slight , watch fox half-clos eye .',\n",
              " 'the fox , sens threat , paus moment , glanc back dog curios .',\n",
              " 'then , flick tail , disappear dens forest , leav dog sigh deepli return peac nap , undisturb fleet encount .',\n",
              " 'the gentl breez rustl leav , scene return quiet still']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "sentance = sent_tokenize(text)\n",
        "\n",
        "sentance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vVKAfH0Wir5",
        "outputId": "722df1b3-4adc-4e58-c861-059a1ff5d8dd"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The quick brown fox jumps over the lazy dog, landing softly on the other side.',\n",
              " 'It runs swiftly across the open field, its paws barely touching the ground as it dodges rocks, trees, and tall grasses.',\n",
              " 'The dog, still lying lazily in the warm sun, only manages to lift its head slightly, watching the fox with half-closed eyes.',\n",
              " 'The fox, sensing no threat, pauses for a moment, glancing back at the dog with curiosity.',\n",
              " 'Then, with a flick of its tail, it disappears into the dense forest, leaving the dog to sigh deeply and return to its peaceful nap, undisturbed by the fleeting encounter.',\n",
              " 'The gentle breeze rustles the leaves, and the scene returns to quiet stillness']"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "for i in range(len(sentance)):\n",
        "  words = word_tokenize(sentance[i])\n",
        "  words= [stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
        "\n",
        "  sentance[i] = \" \".join(words)"
      ],
      "metadata": {
        "id": "DYQB-DJYY-Cs"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XzAT7ucaIsd",
        "outputId": "4fc08d21-8f5d-4154-9f72-c42451f53851"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the quick brown fox jump lazi dog , land soft side .',\n",
              " 'it run swift across open field , paw bare touch ground dodg rock , tree , tall grass .',\n",
              " 'the dog , still lie lazili warm sun , manag lift head slight , watch fox half-clos eye .',\n",
              " 'the fox , sens threat , paus moment , glanc back dog curios .',\n",
              " 'then , flick tail , disappear dens forest , leav dog sigh deepli return peac nap , undisturb fleet encount .',\n",
              " 'the gentl breez rustl leav , scene return quiet still']"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    }
  ]
}