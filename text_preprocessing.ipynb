{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshit6322/FASTAPI_LEARN/blob/main/text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAPlCCh8_WbN"
      },
      "source": [
        "**tokenize**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MnKfUGj_A1I",
        "outputId": "416e281f-d712-4d64-c435-6b4cb64fa9b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Greek king Midas did a good deed for a Satyr.\n",
            "This prompted Dionysus, the god of wine, to grant him a wish.\n",
            "Mida's asked for everything he touched to turn to gold.\n",
            "Dionysus’ warned him not to do so, but Midas could not be swayed.\n",
            "Midas excitedly started touching everything and turning them into gold.\n",
            "Soon, he became hungry.\n"
          ]
        }
      ],
      "source": [
        "paragraph =\"\"\"The Greek king Midas did a good deed for a Satyr.\n",
        "This prompted Dionysus, the god of wine, to grant him a wish.\n",
        "Mida's asked for everything he touched to turn to gold.\n",
        "Dionysus’ warned him not to do so, but Midas could not be swayed.\n",
        "Midas excitedly started touching everything and turning them into gold.\n",
        "Soon, he became hungry.\"\"\"\n",
        "print(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAAV7flvBAwl",
        "outputId": "b8860d81-404c-4d33-be5f-cc69c6df3093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ],
      "source": [
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSQJseL9AlaB",
        "outputId": "01e97036-b0ef-4d91-8d7e-94abb8739762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The Greek king Midas did a good deed for a Satyr.', 'This prompted Dionysus, the god of wine, to grant him a wish.', \"Mida's asked for everything he touched to turn to gold.\", 'Dionysus’ warned him not to do so, but Midas could not be swayed.', 'Midas excitedly started touching everything and turning them into gold.', 'Soon, he became hungry.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_5cIv6dB3cf",
        "outputId": "4fce83ea-242f-4f83-8ecc-84a0251a5461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Greek', 'king', 'Midas', 'did', 'a', 'good', 'deed', 'for', 'a', 'Satyr', '.', 'This', 'prompted', 'Dionysus', ',', 'the', 'god', 'of', 'wine', ',', 'to', 'grant', 'him', 'a', 'wish', '.', 'Mida', \"'s\", 'asked', 'for', 'everything', 'he', 'touched', 'to', 'turn', 'to', 'gold', '.', 'Dionysus', '’', 'warned', 'him', 'not', 'to', 'do', 'so', ',', 'but', 'Midas', 'could', 'not', 'be', 'swayed', '.', 'Midas', 'excitedly', 'started', 'touching', 'everything', 'and', 'turning', 'them', 'into', 'gold', '.', 'Soon', ',', 'he', 'became', 'hungry', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "words = nltk.word_tokenize(paragraph)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlHwvmwSCCMS",
        "outputId": "8925ab03-3259-4f02-815b-c217026346be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Greek', 'king', 'Midas', 'did', 'a', 'good', 'deed', 'for', 'a', 'Satyr', '.', 'This', 'prompted', 'Dionysus', ',', 'the', 'god', 'of', 'wine', ',', 'to', 'grant', 'him', 'a', 'wish', '.', 'Mida', \"'\", 's', 'asked', 'for', 'everything', 'he', 'touched', 'to', 'turn', 'to', 'gold', '.', 'Dionysus', '’', 'warned', 'him', 'not', 'to', 'do', 'so', ',', 'but', 'Midas', 'could', 'not', 'be', 'swayed', '.', 'Midas', 'excitedly', 'started', 'touching', 'everything', 'and', 'turning', 'them', 'into', 'gold', '.', 'Soon', ',', 'he', 'became', 'hungry', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "words = nltk.wordpunct_tokenize(paragraph)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2RUCzgEC-XT",
        "outputId": "07a8c42f-1f3a-4a71-a8e0-bf4e504015a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Greek', 'king', 'Midas', 'did', 'a', 'good', 'deed', 'for', 'a', 'Satyr.', 'This', 'prompted', 'Dionysus', ',', 'the', 'god', 'of', 'wine', ',', 'to', 'grant', 'him', 'a', 'wish.', 'Mida', \"'s\", 'asked', 'for', 'everything', 'he', 'touched', 'to', 'turn', 'to', 'gold.', 'Dionysus’', 'warned', 'him', 'not', 'to', 'do', 'so', ',', 'but', 'Midas', 'could', 'not', 'be', 'swayed.', 'Midas', 'excitedly', 'started', 'touching', 'everything', 'and', 'turning', 'them', 'into', 'gold.', 'Soon', ',', 'he', 'became', 'hungry', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "words = tokenizer.tokenize(paragraph)\n",
        "print(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "358ghqJmEEOj"
      },
      "source": [
        "**stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3zTMnK5EK3o"
      },
      "outputs": [],
      "source": [
        "words =verbs = [\n",
        "    \"running\",\"jumped\",\"speak\",\"writing\",\"reads\",\"sang\",\"dancing\",\"eats\",\"drank\",\"slept\",\"laughing\",\"cries\",\"thought\",\"swimming\",\"drove\",\"flies\",\"cooking\",\"history\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMCsDA4JFY4N",
        "outputId": "ae9531be-b457-4fe6-a1a9-a919cd805f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'jump', 'speak', 'write', 'read', 'sang', 'danc', 'eat', 'drank', 'slept', 'laugh', 'cri', 'thought', 'swim', 'drove', 'fli', 'cook', 'histori']\n"
          ]
        }
      ],
      "source": [
        "from nltk import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyKDlMyFGGIN",
        "outputId": "a60f729a-9231-491a-ac5e-b95dc350798f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'jump', 'speak', 'writ', 'read', 'sang', 'dant', 'eat', 'drank', 'slept', 'laugh', 'cri', 'thought', 'swim', 'drov', 'fli', 'cook', 'hist']\n"
          ]
        }
      ],
      "source": [
        "from nltk import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Wg62TWGeE0",
        "outputId": "cd62e4c2-9416-4132-b4da-5be92abe4fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'jump', 'speak', 'write', 'read', 'sang', 'danc', 'eat', 'drank', 'slept', 'laugh', 'cri', 'thought', 'swim', 'drove', 'fli', 'cook', 'histori']\n"
          ]
        }
      ],
      "source": [
        "from nltk import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Q2D6liKPHt"
      },
      "source": [
        "**word limitizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi6rXSiNG0RH",
        "outputId": "ec13971d-d233-496f-d6f1-fdf72fb48734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'jump', 'speak', 'writ', 'read', 'sang', 'danc', 'eat', 'drank', 'slept', 'laugh', 'crie', 'thought', 'swimm', 'drove', 'flie', 'cook', 'history']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "\n",
        "stemmer = RegexpStemmer('ning$|ed$|able$|ing$|s$', min=4)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPHMJHmBJb__",
        "outputId": "ebfce500-6102-49d0-d478-21d84af1b48f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W_LKcfEInoq",
        "outputId": "7bab8c3f-486a-4d8d-bd38-5fcba8fa0b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'jump', 'speak', 'write', 'read', 'sing', 'dance', 'eat', 'drink', 'sleep', 'laugh', 'cry', 'think', 'swim', 'drive', 'fly', 'cook', 'history']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word,'v') for word in words]\n",
        "print(lemmatized_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoERjQf4KWgu",
        "outputId": "e4707060-ca7a-4164-fbef-1d794fef76c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "go\n"
          ]
        }
      ],
      "source": [
        "lemmetizer = WordNetLemmatizer()\n",
        "lemmatized_word = lemmatizer.lemmatize('going',pos ='v')\n",
        "print(lemmatized_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyRQj6SBLyO6"
      },
      "source": [
        "**Stop Word**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LD_3coyrL5eJ"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"The quick brown fox jumps over the lazy dog, landing softly on the other side. It runs swiftly across the open field, its paws barely touching the ground as it dodges rocks, trees, and tall grasses. The dog, still lying lazily in the warm sun, only manages to lift its head slightly, watching the fox with half-closed eyes. The fox, sensing no threat, pauses for a moment, glancing back at the dog with curiosity. Then, with a flick of its tail, it disappears into the dense forest, leaving the dog to sigh deeply and return to its peaceful nap, undisturbed by the fleeting encounter. The gentle breeze rustles the leaves, and the scene returns to quiet stillness\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALdzXmWJQjOf",
        "outputId": "cedd0b16-29fd-4ec0-dcf7-8c27e18d9995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "khKHn33UMlY0"
      },
      "outputs": [],
      "source": [
        "from  nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vPlMihAPRGll",
        "outputId": "393405fc-51c5-4c5f-ffd2-33724c72124b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "stopwords.words('english')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC1qqYcy1h9j",
        "outputId": "3fc8c81b-d41d-469c-d00d-934f556beb0e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPa-DX-dRktC",
        "outputId": "0d45793a-16d0-4b5f-b371-6376c6467971"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The quick brown fox jumps over the lazy dog, landing softly on the other side.',\n",
              " 'It runs swiftly across the open field, its paws barely touching the ground as it dodges rocks, trees, and tall grasses.',\n",
              " 'The dog, still lying lazily in the warm sun, only manages to lift its head slightly, watching the fox with half-closed eyes.',\n",
              " 'The fox, sensing no threat, pauses for a moment, glancing back at the dog with curiosity.',\n",
              " 'Then, with a flick of its tail, it disappears into the dense forest, leaving the dog to sigh deeply and return to its peaceful nap, undisturbed by the fleeting encounter.',\n",
              " 'The gentle breeze rustles the leaves, and the scene returns to quiet stillness']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "sentance = sent_tokenize(text)\n",
        "\n",
        "sentance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UAeGZfyCSmLw"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "for i in range(len(sentance)):\n",
        "  words = word_tokenize(sentance[i])\n",
        "  words = [stemmer.stem(word) for word in words if word  not in set(stopwords.words('english'))]\n",
        "\n",
        "  sentance[i] = ' '.join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfdDYsF3UYny",
        "outputId": "eaccdd8c-ed12-4e3b-82fa-c275c85eccaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the quick brown fox jump lazi dog , land softli side .',\n",
              " 'it run swiftli across open field , paw bare touch ground dodg rock , tree , tall grass .',\n",
              " 'the dog , still lie lazili warm sun , manag lift head slightli , watch fox half-clos eye .',\n",
              " 'the fox , sens threat , paus moment , glanc back dog curios .',\n",
              " 'then , flick tail , disappear dens forest , leav dog sigh deepli return peac nap , undisturb fleet encount .',\n",
              " 'the gentl breez rustl leav , scene return quiet still']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "sentance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vVKAfH0Wir5",
        "outputId": "a170d8b3-da5e-451b-d558-0dd7cea4d5a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The quick brown fox jumps over the lazy dog, landing softly on the other side.',\n",
              " 'It runs swiftly across the open field, its paws barely touching the ground as it dodges rocks, trees, and tall grasses.',\n",
              " 'The dog, still lying lazily in the warm sun, only manages to lift its head slightly, watching the fox with half-closed eyes.',\n",
              " 'The fox, sensing no threat, pauses for a moment, glancing back at the dog with curiosity.',\n",
              " 'Then, with a flick of its tail, it disappears into the dense forest, leaving the dog to sigh deeply and return to its peaceful nap, undisturbed by the fleeting encounter.',\n",
              " 'The gentle breeze rustles the leaves, and the scene returns to quiet stillness']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "sentance = sent_tokenize(text)\n",
        "\n",
        "sentance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DYQB-DJYY-Cs"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "for i in range(len(sentance)):\n",
        "  words = word_tokenize(sentance[i])\n",
        "  words= [stemmer.stem(word) for word in words if word not in set(stopwords.words(\"english\"))]\n",
        "\n",
        "  sentance[i] = \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XzAT7ucaIsd",
        "outputId": "b4202bf7-ecb1-4d44-e001-24df0455f71a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the quick brown fox jump lazi dog , land soft side .',\n",
              " 'it run swift across open field , paw bare touch ground dodg rock , tree , tall grass .',\n",
              " 'the dog , still lie lazili warm sun , manag lift head slight , watch fox half-clos eye .',\n",
              " 'the fox , sens threat , paus moment , glanc back dog curios .',\n",
              " 'then , flick tail , disappear dens forest , leav dog sigh deepli return peac nap , undisturb fleet encount .',\n",
              " 'the gentl breez rustl leav , scene return quiet still']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "sentance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aue5XDzneaiz",
        "outputId": "88af4f3f-55c2-4dda-c64a-87f198b7560a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The quick brown fox jumps over the lazy dog, landing softly on the other side.',\n",
              " 'It runs swiftly across the open field, its paws barely touching the ground as it dodges rocks, trees, and tall grasses.',\n",
              " 'The dog, still lying lazily in the warm sun, only manages to lift its head slightly, watching the fox with half-closed eyes.',\n",
              " 'The fox, sensing no threat, pauses for a moment, glancing back at the dog with curiosity.',\n",
              " 'Then, with a flick of its tail, it disappears into the dense forest, leaving the dog to sigh deeply and return to its peaceful nap, undisturbed by the fleeting encounter.',\n",
              " 'The gentle breeze rustles the leaves, and the scene returns to quiet stillness']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "lemmatizer = WordNetLemmatizer\n",
        "sentance = sent_tokenize(text)\n",
        "sentance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnLLYQU51wa-",
        "outputId": "2ef2a94d-6798-4cf9-e722-70aa5cfb24fe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "sentance = sent_tokenize(text)\n",
        "\n",
        "for i in range(len(sentance)):\n",
        "  words = word_tokenize(sentance[i])\n",
        "  words= [lemmatizer.lemmatize(word.lower(),pos='v') for word in words if word not in set(stopwords.words(\"english\"))]\n",
        "  sentance[i] = \" \".join(words)\n",
        "sentance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OHOCtzE1RII",
        "outputId": "0df3825a-e163-43e1-8ecc-f106b567b4fa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the quick brown fox jump lazy dog , land softly side .',\n",
              " 'it run swiftly across open field , paw barely touch grind dodge rock , tree , tall grass .',\n",
              " 'the dog , still lie lazily warm sun , manage lift head slightly , watch fox half-closed eye .',\n",
              " 'the fox , sense threat , pause moment , glance back dog curiosity .',\n",
              " 'then , flick tail , disappear dense forest , leave dog sigh deeply return peaceful nap , undisturbed fleet encounter .',\n",
              " 'the gentle breeze rustle leave , scene return quiet stillness']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xRlAuWIH1tSC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAc1kFbnVnEhz/ulzlvjuF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}